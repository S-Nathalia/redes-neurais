{"cells":[{"cell_type":"markdown","metadata":{"id":"bR9pBlj_Q7bO"},"source":["# Import bibliotecas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cHZ6xaDBaGD9"},"outputs":[],"source":["from tensorflow.keras.losses import binary_crossentropy\n","from sklearn.model_selection import train_test_split\n","from google.colab import files\n","import tensorflow as tf\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import nibabel as nib\n","import numpy as np\n","import glob\n","import os\n","\n","seed_val = 1\n","np.random.seed(seed_val)\n","tf.random.set_seed(seed_val)"]},{"cell_type":"markdown","metadata":{"id":"9wvAcLzyJC90"},"source":["# Lendo as imagens\n","\n","Existem imagens de dimens√µes diversas, estou considerando apenas as que tem 320, 320"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28192,"status":"ok","timestamp":1653610218030,"user":{"displayName":"Nathalia Santos","userId":"18223315061685652104"},"user_tz":180},"id":"3iWnpzAwYo_q","outputId":"84740eb9-1116-4cdb-9d87-365af527467a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"liYYa6syBLFC"},"outputs":[],"source":["path_x = '/content/drive/MyDrive/prostate/imagesTr/*.nii'\n","\n","X = []\n","\n","for p in glob.iglob(path_x):\n","    nii_obj = nib.load(p).get_fdata()\n","    slices = np.array(nii_obj).shape[2]\n","    for i in range(slices):\n","        if(len(nii_obj[:, :, i, 0]) == 320):\n","            img = np.array(nii_obj[:, :, i, 0])\n","            mx = np.max(img)\n","            norm = img/mx\n","            norm = np.expand_dims(norm, axis=-1)\n","            norm = tf.convert_to_tensor(norm, dtype=tf.float32)\n","            X.append(norm)\n","        else:\n","            pass\n","\n","\n","X = np.array(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tDEnlBvdK_MJ"},"outputs":[],"source":["path_labels = '/content/drive/MyDrive/prostate/labelsTr/*.nii'\n","\n","labels = []\n","n_classes = 3\n","\n","for p in glob.iglob(path_labels):\n","    nii_obj = nib.load(p).get_fdata()\n","    slices = np.array(nii_obj).shape[2]\n","    \n","    for i in range(slices):\n","        if(len(nii_obj[:, :, i]) == 320):\n","            img = np.array(nii_obj[:, :, i])\n","            img = np.expand_dims(img, axis=-1)\n","            img = tf.convert_to_tensor(img, dtype=tf.int32)\n","\n","            aux = []\n","\n","            for c in range(n_classes):\n","                mask = tf.equal(img[:,:,0], tf.constant(c))\n","                aux.append(tf.cast(mask, dtype=tf.int32))\n","            annotation = tf.stack(aux, axis=2)\n","            labels.append(annotation)\n","        else:\n","            pass\n","\n","labels = np.array(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FY_Eb6ZH_Evh"},"outputs":[],"source":["X_train, xtest, y_train, ytest = train_test_split(X, labels, train_size=0.6, shuffle=True)\n","X_val, X_test, y_val, y_test = train_test_split(xtest, ytest, train_size=0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1653610260490,"user":{"displayName":"Nathalia Santos","userId":"18223315061685652104"},"user_tz":180},"id":"GJ8SIgKJKSNQ","outputId":"6f9cdac0-5c97-4f46-da51-134dc063f5b0"},"outputs":[{"data":{"text/plain":["(540, 320, 320, 1)"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["X.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1653610260491,"user":{"displayName":"Nathalia Santos","userId":"18223315061685652104"},"user_tz":180},"id":"ni6j6S2d_Zqc","outputId":"fa0dd1b8-b710-47d1-d7db-ed822a9f4de7"},"outputs":[{"name":"stdout","output_type":"stream","text":["(324, 320, 320, 1)\n","(324, 320, 320, 3)\n","(108, 320, 320, 1)\n","(108, 320, 320, 3)\n","(108, 320, 320, 1)\n","(108, 320, 320, 3)\n"]}],"source":["print(X_train.shape)\n","print(y_train.shape)\n","print(X_test.shape)\n","print(y_test.shape)\n","print(X_val.shape)\n","print(y_val.shape)"]},{"cell_type":"markdown","metadata":{"id":"qEY0AWetks96"},"source":["# Compilando rede U-net\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z9-gGyYVY9v9"},"outputs":[],"source":["class Rede(tf.keras.models.Model):\n","\n","    def __init__(self, n_filters, n_classes):\n","        super(Rede, self).__init__()\n","        self.n_filters = n_filters\n","        self.n_classes = n_classes\n","\n","        self.max_pooling = tf.keras.layers.MaxPooling2D(pool_size=(2,2))\n","\n","        self.encoder_block_0_conv_1 = tf.keras.layers.Conv2D(\n","            self.n_filters, (5,5), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.encoder_block_0_conv_2 = tf.keras.layers.Conv2D(\n","            self.n_filters, (5,5), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.encoder_block_0_BN = tf.keras.layers.BatchNormalization()\n","\n","        self.encoder_block_1_conv_1 = tf.keras.layers.Conv2D(\n","            self.n_filters*2, (5,5), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.encoder_block_1_conv_2 = tf.keras.layers.Conv2D(\n","            self.n_filters*2, (5,5), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.encoder_block_1_BN = tf.keras.layers.BatchNormalization()\n","\n","        self.encoder_block_2_conv_1 = tf.keras.layers.Conv2D(\n","            self.n_filters*4, (5,5), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.encoder_block_2_conv_2 = tf.keras.layers.Conv2D(\n","            self.n_filters*4, (5,5), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.encoder_block_2_BN = tf.keras.layers.BatchNormalization()\n","\n","        self.encoder_block_3_conv_1 = tf.keras.layers.Conv2D(\n","            self.n_filters*8, (5,5), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.encoder_block_3_conv_2 = tf.keras.layers.Conv2D(\n","            self.n_filters*8, (5,5), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.encoder_block_3_BN = tf.keras.layers.BatchNormalization()\n","\n","        self.encoder_block_4_conv_1 = tf.keras.layers.Conv2D(\n","            self.n_filters*16, (5,5), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.encoder_block_4_conv_2 = tf.keras.layers.Conv2D(\n","            self.n_filters*16, (5,5), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.encoder_block_4_BN = tf.keras.layers.BatchNormalization()\n","\n","        ########################################################################\n","\n","        self.decoder_block_0_convT = tf.keras.layers.Conv2DTranspose(\n","            self.n_filters*8, (2,2), strides=(2,2), padding='same', kernel_initializer=\"he_normal\")\n","        self.decoder_block_0_conv_1 = tf.keras.layers.Conv2D(\n","            self.n_filters*8, (2,2), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.decoder_block_0_conv_2 = tf.keras.layers.Conv2D(\n","            self.n_filters*8, (2,2), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","\n","        self.decoder_block_1_convT = tf.keras.layers.Conv2DTranspose(\n","            self.n_filters*4, (2,2), strides=(2,2), padding='same', kernel_initializer=\"he_normal\")\n","        self.decoder_block_1_conv_1 = tf.keras.layers.Conv2D(\n","            self.n_filters*4, (2,2), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.decoder_block_1_conv_2 = tf.keras.layers.Conv2D(\n","            self.n_filters*4, (2,2), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","\n","        self.decoder_block_2_convT = tf.keras.layers.Conv2DTranspose(\n","            self.n_filters*2, (2,2), strides=(2,2), padding='same', kernel_initializer=\"he_normal\")\n","        self.decoder_block_2_conv_1 = tf.keras.layers.Conv2D(\n","            self.n_filters*2, (2,2), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.decoder_block_2_conv_2 = tf.keras.layers.Conv2D(\n","            self.n_filters*2, (2,2), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","\n","        self.decoder_block_3_convT = tf.keras.layers.Conv2DTranspose(\n","            self.n_filters, (2,2), strides=(2,2), padding='same', kernel_initializer=\"he_normal\")\n","        self.decoder_block_3_conv_1 = tf.keras.layers.Conv2D(\n","            self.n_filters, (2,2), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","        self.decoder_block_3_conv_2 = tf.keras.layers.Conv2D(\n","            self.n_filters, (2,2), activation='relu',padding='same', kernel_initializer=\"he_normal\")\n","\n","        self.decoder_final = tf.keras.layers.Conv2D(\n","            self.n_classes, (1,1), activation='softmax', padding='same')\n","\n","        self.dropout = tf.keras.layers.Dropout(0.3)\n","\n","    \n","    def call(self, inputs, training=True):\n","\n","        out = self.encoder_block_0_conv_1(inputs)\n","        out = self.encoder_block_0_conv_2(out)\n","        # out = self.encoder_block_0_BN(out)\n","        out = self.max_pooling(out)\n","        skip_0 = out\n","\n","        out = self.encoder_block_1_conv_1(out)\n","        out = self.encoder_block_1_conv_2(out)\n","        # out = self.encoder_block_1_BN(out)\n","        out = self.max_pooling(out)\n","        skip_1 = out\n","\n","        out = self.encoder_block_2_conv_1(out)\n","        out = self.encoder_block_2_conv_2(out)\n","        # out = self.encoder_block_2_BN(out)\n","        out = self.max_pooling(out)\n","        skip_2 = out\n","\n","        out = self.encoder_block_3_conv_1(out)\n","        out = self.encoder_block_3_conv_2(out)\n","        out = self.dropout(out, training=training)\n","        # out = self.encoder_block_3_BN(out)\n","        out = self.max_pooling(out)\n","        skip_3 = out\n","\n","        out = self.encoder_block_4_conv_1(out)\n","        out = self.encoder_block_4_conv_2(out)\n","        out = self.dropout(out, training=training)\n","        # out = self.encoder_block_4_BN(out)\n","\n","        ########################################################################\n","        out = tf.keras.layers.concatenate([out, skip_3])\n","        # out = tf.keras.layers.concatenate([out, skip_2])\n","\n","        out = self.decoder_block_0_convT(out)\n","        out = tf.keras.layers.concatenate([out, skip_2])\n","        out = self.decoder_block_0_conv_1(out)\n","        out = self.decoder_block_0_conv_2(out)\n","\n","        out = self.decoder_block_1_convT(out)\n","        out = tf.keras.layers.concatenate([out, skip_1])\n","        out = self.decoder_block_1_conv_1(out)\n","        out = self.decoder_block_1_conv_2(out)\n","\n","        out = self.decoder_block_2_convT(out)\n","        out = tf.keras.layers.concatenate([out, skip_0])\n","        out = self.decoder_block_2_conv_1(out)\n","        out = self.decoder_block_2_conv_2(out)\n","\n","        out = self.decoder_block_3_convT(out)\n","        out = self.decoder_block_3_conv_1(out)\n","        out = self.decoder_block_3_conv_2(out)\n","\n","        out = self.decoder_final(out)\n","\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S04OMRTW8Bu8"},"outputs":[],"source":["model = None\n","model = Rede(32, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5rdBqHAQC3Fz"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","54/54 [==============================] - 1023s 19s/step - loss: 0.8197 - mean_io_u_1: 0.3612 - val_loss: 0.1842 - val_mean_io_u_1: 0.3337\n","Epoch 2/30\n","54/54 [==============================] - 1022s 19s/step - loss: 0.1210 - mean_io_u_1: 0.5074 - val_loss: 0.1033 - val_mean_io_u_1: 0.4037\n","Epoch 3/30\n","54/54 [==============================] - 1018s 19s/step - loss: 0.0841 - mean_io_u_1: 0.6989 - val_loss: 0.0862 - val_mean_io_u_1: 0.4747\n","Epoch 4/30\n","54/54 [==============================] - 1016s 19s/step - loss: 0.0839 - mean_io_u_1: 0.6381 - val_loss: 0.0752 - val_mean_io_u_1: 0.5804\n","Epoch 5/30\n","54/54 [==============================] - 1015s 19s/step - loss: 0.0784 - mean_io_u_1: 0.7094 - val_loss: 0.0744 - val_mean_io_u_1: 0.7494\n","Epoch 6/30\n","17/54 [========\u003e.....................] - ETA: 10:40 - loss: 0.0820 - mean_io_u_1: 0.7076"]}],"source":["epocas = 30\n","lr = 0.001\n","otimizador = tf.keras.optimizers.Adam(learning_rate=lr)\n","loss_fn = tf.keras.losses.CategoricalCrossentropy()\n","metrics=[tf.keras.metrics.MeanIoU(num_classes=3)]\n","\n","\n","model.compile(optimizer=otimizador,\n","              loss=loss_fn,\n","              metrics=[metrics])\n","\n","history = model.fit(X_train, \n","                    y_train, \n","                    epochs=epocas, \n","                    batch_size=6, \n","                    shuffle=True, \n","                    validation_data=(X_val, y_val))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bz78lI_JDrRc"},"outputs":[],"source":["def plot_loss(history, title):\n","    plt.plot(history.history['loss'], label='train-loss', color='purple')\n","    plt.plot(history.history['val_loss'], label='val-loss', color='blue')\n","    plt.title(f'Train and validation loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.savefig(f'{title}.png')\n","    files.download(f'{title}.png')\n","\n","exp = 'loss exp_4'\n","plot_loss(history, exp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h7NmPRp6ZkmZ"},"outputs":[],"source":["model.evaluate(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IwjnDobhLfla"},"outputs":[],"source":["model.save_weights('/content/')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B6oLDew2ENtI"},"outputs":[],"source":["class Visualizer():\n","    def __init__(self, model, X_test, y_test, n_classes):\n","        self.model = model\n","        self.X_test = X_test\n","        self.y_test = y_test\n","        self.n_classes = n_classes\n","        self.colors = sns.color_palette(None, self.n_classes)\n","\n","    def __give_color(self, y):\n","        seg_img = np.zeros((y.shape[0], y.shape[1], 3)).astype('float')\n","        for c in range(self.n_classes):\n","            segc = (y == c)\n","            print(self.colors[c])\n","            seg_img[:, :, 0] += segc * (self.colors[c][0] * 255.0)\n","            seg_img[:, :, 1] += segc * (self.colors[c][1] * 255.0)\n","            seg_img[:, :, 2] += segc * (self.colors[c][2] * 255.0)\n","\n","        return seg_img\n","\n","    def run(self, sample_idx):\n","        fig = plt.figure()\n","        X = self.X_test[sample_idx]\n","        y = self.__give_color(np.argmax(self.y_test[sample_idx], axis=2))\n","        y_pred = self.model.predict(X[np.newaxis, ...])\n","        y_pred = self.__give_color(np.argmax(y_pred[0, :, :, :], axis=2))\n","\n","        f, ax = plt.subplots(nrows=1, ncols=3, figsize=(15,8))\n","\n","        ax[0].imshow(X[:, :, 0], cmap='gray')\n","        ax[0].set_title('X')\n","        ax[0].axis('off')\n","\n","        ax[1].imshow(y.astype(np.uint8))\n","        ax[1].set_title('Mask')\n","        ax[1].axis('off')\n","\n","        ax[2].imshow(y_pred.astype(np.uint8))\n","        ax[2].set_title('Mask predicted')\n","        ax[2].axis('off')\n","        plt.tight_layout()\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TpBmIcPfHzHc"},"outputs":[],"source":["visualizer = Visualizer(model=model,\n","                        X_test=X_test,\n","                        y_test=y_test,\n","                        n_classes=3)\n","for x in range(100):\n","  if x%25==0:\n","    visualizer.run(sample_idx=x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fMy3wKMl7_U4"},"outputs":[],"source":["unet3_1 = [\n","[15, 1],[15, 1],[2, 1],\n","\n","[13, 1],[13, 1],[2, 1],\n","\n","[11, 1],[11, 1],[2, 1],\n","\n","[7, 1],[7, 1],[2, 1],\n","\n","[5, 1],[5, 1],\n","\n","[5, 2],[7, 1],[7, 1],\n","\n","[5, 2],[11, 1],[11, 1],\n","\n","[5, 2],[13, 1],[13, 1],\n","\n","[5, 2],[15, 1],[15, 1],\n","\n","[1, 1]]\n","\n","unetA = [\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],\n","\n","[3, 2],[3, 1],[3, 1],\n","\n","[3, 2],[3, 1],[3, 1],\n","\n","[3, 2],[3, 1],[3, 1],\n","\n","[3, 2],[3, 1],[3, 1],\n","\n","[1, 1]]\n","\n","unetB = [\n","[5, 1],[5, 1],[2, 1],\n","\n","[5, 1],[5, 1],[2, 1],\n","\n","[5, 1],[5, 1],[2, 1],\n","\n","[5, 1],[5, 1],\n","\n","[5, 2],[5, 1],[5, 1],\n","\n","[5, 2],[5, 1],[5, 1],\n","\n","[5, 2],[5, 1],[5, 1],\n","\n","[1, 1]]\n","\n","unet3_2 = [\n","[3, 1],[3, 1],[2, 1],\n","\n","[5, 1],[5, 1],[2, 1],\n","\n","[7, 1],[7, 1],[2, 1],\n","\n","[11, 1],[11, 1],[2, 1],\n","\n","[13, 1],[13, 1],\n","\n","\n","[5, 2],[5, 1],[5, 1],\n","\n","[5, 2],[7, 1],[7, 1],\n","\n","[5, 2],[11, 1],[11, 1],\n","\n","[5, 2],[13, 1],[13, 1],\n","\n","[1, 1]]\n","\n","unet3_3 = [\n","[7, 1],[7, 1],[2, 1],\n","\n","[5, 1],[5, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],\n","\n","\n","[3, 2],[3, 1],[3, 1],\n","\n","[5, 2],[5, 1],[5, 1],\n","\n","[5, 2],[5, 1],[5, 1],\n","\n","[3, 2],[7, 1],[7, 1],\n","\n","[1, 1]]\n","\n","unet3_4 = [\n","[5, 1],[5, 1],[2, 1],\n","\n","[5, 1],[5, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[2, 1],[2, 1],[2, 1],\n","\n","[2, 1],[2, 1],\n","\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[3, 2],[3, 1],[3, 1],\n","\n","[5, 2],[5, 1],[5, 1],\n","\n","[5, 2],[5, 1],[5, 1],\n","\n","[1, 1]]\n","\n","unet3_5 = [\n","[25, 1],[25, 1],[2, 1],\n","\n","[5, 1],[5, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[2, 1],[2, 1],[2, 1],\n","\n","[2, 1],[2, 1],\n","\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[3, 2],[3, 1],[3, 1],\n","\n","[5, 2],[5, 1],[5, 1],\n","\n","[5, 2],[5, 1],[5, 1],\n","\n","[1, 1]]\n","\n","unet3_6 = [\n","[5, 1],[5, 1],[2, 1],\n","\n","[5, 1],[5, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],\n","\n","\n","[3, 2],[3, 1],[3, 1],\n","\n","[3, 2],[3, 1],[3, 1],\n","\n","[3, 2],[5, 1],[5, 1],\n","\n","[3, 2],[5, 1],[5, 1],\n","\n","[1, 1]]\n","\n","unet3_7 = [\n","[2, 1],[2, 1],[2, 1],\n","\n","[2, 1],[2, 1],[2, 1],\n","\n","[2, 1],[2, 1],[2, 1],\n","\n","[2, 1],[2, 1],[2, 1],\n","\n","[2, 1],[2, 1],\n","\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[1, 1]]\n","\n","unet4 = [\n","[5, 1],[5, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],\n","\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[1, 1]] \n","\n","unet41 = [[5, 1],[5, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1],[2, 1],\n","\n","[3, 1],[3, 1]]\n","\n","unet42 = [[2, 2],[2, 1],[2, 1],\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[2, 2],[2, 1],[2, 1],\n","\n","[1, 1]]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":271,"status":"ok","timestamp":1653610343820,"user":{"displayName":"Nathalia Santos","userId":"18223315061685652104"},"user_tz":180},"id":"8wq8PyHbbYbH","outputId":"9e5d17c2-9da9-4135-db45-ec8f1c2fcffd"},"outputs":[{"name":"stdout","output_type":"stream","text":["A 174\n","B 175\n","3.1 900\n","3.2 740\n","3.3 374\n","3.4 293\n","3.5 333\n","3.6 278\n","3.7 89\n","4 103\n","4encoder 28\n","4decoder 75\n"]}],"source":["def calcula_trf(dados):\n","\n","    trf_ant = 0\n","    s = 1\n","    for dado in dados:\n","        k = dado[0]\n","        trf = trf_ant + ((k - 1) * s)\n","        # print(f'TRF: {trf_ant} + {(k - 1)} * {s} = {trf}')\n","        trf_ant = trf\n","        s = s * dado[1]\n","        \n","    return trf\n","\n","print(f'A {calcula_trf(unetA)}')\n","print(f'B {calcula_trf(unetB)}')\n","print(f'3.1 {calcula_trf(unet3_1)}')\n","print(f'3.2 {calcula_trf(unet3_2)}')\n","print(f'3.3 {calcula_trf(unet3_3)}')\n","print(f'3.4 {calcula_trf(unet3_4)}')\n","print(f'3.5 {calcula_trf(unet3_5)}')\n","print(f'3.6 {calcula_trf(unet3_6)}')\n","print(f'3.7 {calcula_trf(unet3_7)}')\n","print(f'4 {calcula_trf(unet4)}')\n","print(f'4encoder {calcula_trf(unet41)}')\n","print(f'4decoder {calcula_trf(unet42)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TYtWhBH4mPE5"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Lista 3 - u-net.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}